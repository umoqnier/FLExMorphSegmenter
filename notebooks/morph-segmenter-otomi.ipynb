{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizador morfologico y generador de glosa auomática\n",
    "\n",
    "## Replica del experimento\n",
    "\n",
    "Esta es una replica del experimento realizado por [@theSarahRu](https://github.com/theSarahRu/FLExMorphSegmenter) donde realiza análisis morfológico y glosado de afijos para una lengua de bajos recursos llamada Lezgi [lez]. Lezgi es una de las [lenguas caucásicas nororientales](https://es.wikipedia.org/wiki/Lenguas_cauc%C3%A1sicas_nororientales) y es hablada entre Rusia y Azerbaiyán. La idea central es que su trabajo pueda ser replicado para cualquier lengua que cuente con 2000 a 3000 **palabras** correctamente etiquetadas. El programa se considera exitoso si alcanza el 80% de *accuracy*. \n",
    "\n",
    "En esta replica se utilizará la lengua del otomí y en particular la variante del valle del mezquital (hñahñu). Se utilizará el corpus etiquetado del Maestro en Lingüistica Computacional Victor Germán Mijangos. El corpus consta de `1705` **oraciones** etiquetadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiendo modelo previamente entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'tsunkua_uniq.crfsuite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seccionando datos en test y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vic_data():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open(\"uniq_corpus.txt\", encoding='utf-8', mode='r') as f:\n",
    "        plain_text = f.read()\n",
    "    raw_data = plain_text.split('\\n')\n",
    "    # El formato del corpus permite usar eval()\n",
    "    return [eval(row) for row in raw_data]\n",
    "\n",
    "\n",
    "def WordsToLetter(wordlists):\n",
    "    '''\n",
    "    Takes data from vic data: [[[[[[morpheme, gloss], pos],...],words],sents]].\n",
    "    Returns [[[[[letter, POS, BIO-label],...],words],sents]]\n",
    "    '''\n",
    "    letterlists = []\n",
    "    for i, phrase in enumerate(wordlists):\n",
    "        sent = []\n",
    "        for lexeme in phrase:\n",
    "            palabra = ''\n",
    "            word = []\n",
    "            #Skip POS label\n",
    "            for morpheme in lexeme[:-1]:\n",
    "                palabra += ''.join([l for l in morpheme[0]])\n",
    "                #use gloss as BIO label\n",
    "                label = morpheme[1]\n",
    "                #Break morphemes into letters\n",
    "                for i in range(len(morpheme[0])):\n",
    "                    letter = [morpheme[0][i]]  # Adding ascii for encoding\n",
    "                    #add POS label to each letter\n",
    "                    letter.append(lexeme[-1])\n",
    "                    #add BIO label\n",
    "                    if i == 0:\n",
    "                        letter.append('B-' + label)\n",
    "                    else:\n",
    "                        letter.append('I-' + label)                               \n",
    "                    word.append(letter)                    \n",
    "            sent.append(word)            \n",
    "        letterlists.append(sent)\n",
    "    return letterlists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 1350\n",
      "Test data: 338\n",
      "Total data: 1688\n",
      "Oracion ejemplo:  [[['p', 'v', 'B-it'], ['i', 'v', 'I-it'], ['t', 'v', 'B-1.prf'], ['ó', 'v', 'I-1.prf'], ['t', 'v', 'B-stem'], ['ó', 'v', 'I-stem'], ['n', 'v', 'I-stem'], ['y', 'v', 'B-lim'], ['ι', 'v', 'I-lim'], [\"'\", 'v', 'I-lim']], [['y', 'det', 'B-det.pl'], ['ι', 'det', 'I-det.pl']], [['t', 'unkwn', 'B-dim'], ['s', 'unkwn', 'I-dim'], ['i', 'unkwn', 'I-dim'], ['b', 'unkwn', 'B-stem'], ['e', 'unkwn', 'I-stem'], ['s', 'unkwn', 'I-stem'], ['e', 'unkwn', 'I-stem'], ['r', 'unkwn', 'I-stem'], ['r', 'unkwn', 'I-stem'], ['a', 'unkwn', 'I-stem'], ['y', 'unkwn', 'B-lim'], ['ι', 'unkwn', 'I-lim'], [\"'\", 'unkwn', 'I-lim']], [['p', 'cnj', 'B-stem'], ['o', 'cnj', 'I-stem'], ['r', 'cnj', 'I-stem'], ['k', 'cnj', 'I-stem'], ['e', 'cnj', 'I-stem']], [['m', 'obl', 'B-stem'], ['e', 'obl', 'I-stem']], [['g', 'v', 'B-stem'], ['u', 'v', 'I-stem'], ['s', 'v', 'I-stem'], ['t', 'v', 'I-stem'], ['a', 'v', 'I-stem']]]\n"
     ]
    }
   ],
   "source": [
    "vic_data = get_vic_data()\n",
    "train_data, test_data = train_test_split(WordsToLetter(vic_data), test_size=0.2)\n",
    "print(\"Train data:\", len(train_data))\n",
    "print(\"Test data:\", len(test_data))\n",
    "print(\"Total data:\", len(train_data) + len(test_data))\n",
    "print(\"Oracion ejemplo: \", train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis y extracción de features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definiendo funciones de analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(sent):\n",
    "    '''Takes data as [[[[[letter, POS, BIO-label],...],words],sents]].\n",
    "    Returns list of words with characters as features list: [[[[[letterfeatures],POS,BIO-label],letters],words]]'''\n",
    "    \n",
    "    featurelist = []\n",
    "    senlen = len(sent)\n",
    "\n",
    "    # TODO: Optimizar los parametros hardcode para el otomí. Se probaran nuevos parámetro\n",
    "    #each word in a sentence\n",
    "    for i in range(senlen):\n",
    "        word = sent[i]\n",
    "        wordlen = len(word)\n",
    "        lettersequence = ''\n",
    "        #each letter in a word\n",
    "        for j in range(wordlen):\n",
    "            letter = word[j][0]\n",
    "            #gathering previous letters\n",
    "            lettersequence += letter\n",
    "            #ignore     digits\n",
    "            if not letter.isdigit():\n",
    "                features = [\n",
    "                    'bias',\n",
    "                    'letterLowercase=' + letter.lower(),\n",
    "                    'postag=' + word[j][1],\n",
    "                ] \n",
    "                #position of word in sentence and pos tags sequence\n",
    "                if i > 0:\n",
    "                    features.append('prevpostag=' + sent[i-1][0][1])\n",
    "                    if i != senlen-1:\n",
    "                        features.append('nxtpostag=' + sent[i+1][0][1])\n",
    "                    else:\n",
    "                        features.append('EOS')\n",
    "                else:\n",
    "                    features.append('BOS')\n",
    "                    #Don't get pos tag if sentence is 1 word long\n",
    "                    if i != senlen-1:\n",
    "                        features.append('nxtpostag=' + sent[i+1][0][1])\n",
    "                #position of letter in word\n",
    "                if j == 0:\n",
    "                    features.append('BOW')\n",
    "                elif j == wordlen-1:\n",
    "                    features.append('EOW')\n",
    "                else:\n",
    "                    features.append('letterposition=-%s' % str(wordlen-1-j))\n",
    "                #letter sequences before letter\n",
    "                if j >= 4:\n",
    "                    features.append('prev4letters=' + lettersequence[j-4:j].lower() + '>')\n",
    "                if j >= 3:\n",
    "                    features.append('prev3letters=' + lettersequence[j-3:j].lower() + '>')\n",
    "                if j >= 2:\n",
    "                    features.append('prev2letters=' + lettersequence[j-2:j].lower() + '>')\n",
    "                if j >= 1:\n",
    "                    features.append('prevletter=' + lettersequence[j-1:j].lower() + '>')\n",
    "                #letter sequences after letter\n",
    "                if j <= wordlen-2:\n",
    "                    nxtlets = word[j+1][0]\n",
    "                    features.append('nxtletter=<' + nxtlets.lower())\n",
    "                if j <= wordlen-3:\n",
    "                    nxtlets += word[j+2][0]\n",
    "                    features.append('nxt2letters=<' + nxtlets.lower())\n",
    "                if j <= wordlen-4:\n",
    "                    nxtlets += word[j+3][0]\n",
    "                    features.append('nxt3letters=<' + nxtlets.lower())\n",
    "                if j <= wordlen-5:\n",
    "                    nxtlets += word[j+4][0]\n",
    "                    features.append('nxt4letters=<' + nxtlets.lower())\n",
    "                \n",
    "            featurelist.append([f.encode('utf-8') for f in features])  # Add encoding for pysrfsuite\n",
    "    \n",
    "    return featurelist\n",
    "\n",
    "\n",
    "def extractLabels(sent):\n",
    "    labels = []\n",
    "    for word in sent:\n",
    "        for letter in word:\n",
    "            labels.append(letter[2].encode('utf-8'))\n",
    "    return labels\n",
    "\n",
    "\n",
    "def extractTokens(sent):\n",
    "    tokens = []\n",
    "    for word in sent:\n",
    "        for letter in word:\n",
    "            tokens.append(letter[0])\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def sent2features(data):\n",
    "    return [extractFeatures(sent) for sent in data]\n",
    "\n",
    "\n",
    "def sent2labels(data):\n",
    "    return [extractLabels(sent) for sent in data]\n",
    "\n",
    "\n",
    "def sent2tokens(data):\n",
    "    return [extractTokens(sent) for sent in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train ejemplo:  [[b'bias', b'letterLowercase=p', b'postag=v', b'BOS', b'nxtpostag=det', b'BOW', b'nxtletter=<i', b'nxt2letters=<it', b'nxt3letters=<it\\xc3\\xb3', b'nxt4letters=<it\\xc3\\xb3t'], [b'bias', b'letterLowercase=i', b'postag=v', b'BOS', b'nxtpostag=det', b'letterposition=-8', b'prevletter=p>', b'nxtletter=<t', b'nxt2letters=<t\\xc3\\xb3', b'nxt3letters=<t\\xc3\\xb3t', b'nxt4letters=<t\\xc3\\xb3t\\xc3\\xb3'], [b'bias', b'letterLowercase=t', b'postag=v', b'BOS', b'nxtpostag=det', b'letterposition=-7', b'prev2letters=pi>', b'prevletter=i>', b'nxtletter=<\\xc3\\xb3', b'nxt2letters=<\\xc3\\xb3t', b'nxt3letters=<\\xc3\\xb3t\\xc3\\xb3', b'nxt4letters=<\\xc3\\xb3t\\xc3\\xb3n'], [b'bias', b'letterLowercase=\\xc3\\xb3', b'postag=v', b'BOS', b'nxtpostag=det', b'letterposition=-6', b'prev3letters=pit>', b'prev2letters=it>', b'prevletter=t>', b'nxtletter=<t', b'nxt2letters=<t\\xc3\\xb3', b'nxt3letters=<t\\xc3\\xb3n', b'nxt4letters=<t\\xc3\\xb3ny'], [b'bias', b'letterLowercase=t', b'postag=v', b'BOS', b'nxtpostag=det', b'letterposition=-5', b'prev4letters=pit\\xc3\\xb3>', b'prev3letters=it\\xc3\\xb3>', b'prev2letters=t\\xc3\\xb3>', b'prevletter=\\xc3\\xb3>', b'nxtletter=<\\xc3\\xb3', b'nxt2letters=<\\xc3\\xb3n', b'nxt3letters=<\\xc3\\xb3ny', b'nxt4letters=<\\xc3\\xb3ny\\xce\\xb9']]\n",
      "\n",
      "y Train ejemplo:  [b'B-it', b'I-it', b'B-1.prf', b'I-1.prf', b'B-stem', b'I-stem', b'I-stem', b'B-lim', b'I-lim', b'I-lim', b'B-det.pl', b'I-det.pl', b'B-dim', b'I-dim', b'I-dim', b'B-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem', b'B-lim', b'I-lim', b'I-lim', b'B-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem', b'B-stem', b'I-stem', b'B-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem']\n",
      "\n",
      "X Test ejemplo:  [[b'bias', b'letterLowercase=b', b'postag=v', b'BOS', b'nxtpostag=obl', b'BOW', b'nxtletter=<i', b\"nxt2letters=<i'\", b\"nxt3letters=<i'\\xce\\xbc\", b\"nxt4letters=<i'\\xce\\xbcn\"], [b'bias', b'letterLowercase=i', b'postag=v', b'BOS', b'nxtpostag=obl', b'letterposition=-5', b'prevletter=b>', b\"nxtletter=<'\", b\"nxt2letters=<'\\xce\\xbc\", b\"nxt3letters=<'\\xce\\xbcn\", b\"nxt4letters=<'\\xce\\xbcng\"], [b'bias', b\"letterLowercase='\", b'postag=v', b'BOS', b'nxtpostag=obl', b'letterposition=-4', b'prev2letters=bi>', b'prevletter=i>', b'nxtletter=<\\xce\\xbc', b'nxt2letters=<\\xce\\xbcn', b'nxt3letters=<\\xce\\xbcng', b'nxt4letters=<\\xce\\xbcng\\xc3\\xad'], [b'bias', b'letterLowercase=\\xce\\xbc', b'postag=v', b'BOS', b'nxtpostag=obl', b'letterposition=-3', b\"prev3letters=bi'>\", b\"prev2letters=i'>\", b\"prevletter='>\", b'nxtletter=<n', b'nxt2letters=<ng', b'nxt3letters=<ng\\xc3\\xad'], [b'bias', b'letterLowercase=n', b'postag=v', b'BOS', b'nxtpostag=obl', b'letterposition=-2', b\"prev4letters=bi'\\xce\\xbc>\", b\"prev3letters=i'\\xce\\xbc>\", b\"prev2letters='\\xce\\xbc>\", b'prevletter=\\xce\\xbc>', b'nxtletter=<g', b'nxt2letters=<g\\xc3\\xad']]\n",
      "\n",
      "y Test ejemplo:  [b'B-3.cpl', b'I-3.cpl', b'B-stem', b'I-stem', b'I-stem', b'B-1.obj', b'I-1.obj', b'B-stem', b'I-stem', b'I-stem', b'B-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem', b'B-1.icp', b'I-1.icp', b'B-ctrf', b'I-ctrf', b'B-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem', b'I-stem']\n"
     ]
    }
   ],
   "source": [
    "X_train = sent2features(train_data)\n",
    "y_train = sent2labels(train_data)\n",
    "\n",
    "X_test = sent2features(test_data)\n",
    "y_test = sent2labels(test_data)\n",
    "\n",
    "# Se codifican los ejemplos utf-8 para evitar problemas con pycrfsuite\n",
    "print(\"X Train ejemplo: \", X_train[0][:5])\n",
    "print(\"\\ny Train ejemplo: \", y_train[0])\n",
    "print(\"\\nX Test ejemplo: \", X_test[0][:5])\n",
    "print(\"\\ny Test ejemplo: \", y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "\n",
    "# Set training parameters. L-BFGS is default. Using Elastic Net (L1 + L2) regularization.\n",
    "trainer.set_params({\n",
    "        'c1': 1.0,  # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 50  # early stopping\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si existe un modelo previamente entrenado se utilizará ese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENANDO...\n",
      "Fin del entrenamiento\n",
      "CPU times: user 2min 58s, sys: 200 ms, total: 2min 58s\n",
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The program saves the trained model to a file:\n",
    "\n",
    "if not os.path.isfile(model_filename):\n",
    "    print(\"ENTRENANDO...\")\n",
    "    trainer.train(model_filename)\n",
    "else:\n",
    "    print(\"Usando modelo pre-entrenado >>\", model_filename)\n",
    "print(\"Fin del entrenamiento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos actuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsunkua_50.crfsuite\n",
      "tsunkua.crfsuite\n",
      "tsunkua_mod.crfsuite\n",
      "tsunkua_old.crfsuite\n",
      "tsunkua_uniq.crfsuite\n"
     ]
    }
   ],
   "source": [
    "!ls | grep tsunkua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haciendo predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7fe427f2e358>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usará el modelo entrenado para hacer la predicción de solo una sentencia del test data. Las etiquetas predecidas son mostradas y se comparan con las etiquetas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letras de la sentencia: b  i  '  μ  n  g  í  p  o  r  m  e  d  i  o  d  í  m  á  n  t  s  o  p  h  ó\n",
      "\n",
      "Predecidas  |  Correctas\n",
      "B-3.cpl        B-3.cpl\n",
      "I-3.cpl        I-3.cpl\n",
      "B-stem        B-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "B-1.obj        B-1.obj\n",
      "I-1.obj        I-1.obj\n",
      "B-stem        B-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "B-stem        B-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "B-1.icp        B-1.icp\n",
      "I-1.icp        I-1.icp\n",
      "B-ctrf        B-ctrf\n",
      "I-ctrf        I-ctrf\n",
      "B-stem        B-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n",
      "I-stem        I-stem\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_data[0]\n",
    "print('Letras de la sentencia:', '  '.join(extractTokens(example_sent)), end='\\n')\n",
    "print(\"\\nPredecidas  |  Correctas\")\n",
    "for p, c in zip(tagger.tag(extractFeatures(example_sent)), extractLabels(example_sent)):\n",
    "    print(f\"{p}        {c.decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones de etiquetas BIO en el test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_test = labels_decoder(y_test)\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Obteniendo el *accuracy* pra tener una evaluación del rendimiento del modelo entrenado. El *accuracy* se obtiene con la siguiente ecuación:\n",
    "\n",
    "$$accuracy = \\frac{etiquetas\\ predichas\\ correctamente}{total\\ de\\ etiquetas}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score>  0.9621939510321651\n"
     ]
    }
   ],
   "source": [
    "def accuracy_score(y_test, y_pred):\n",
    "    right, total = 0, 0\n",
    "    for tests, predictions in zip(y_test, y_pred):\n",
    "        total += len(tests)\n",
    "        for t, p in zip(tests, predictions):\n",
    "            if t == p:\n",
    "                right += 1\n",
    "    return right / total\n",
    "print(\"Accuracy Score> \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reportes completos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countMorphemes(morphlist):\n",
    "    counts = {}\n",
    "    for morpheme in morphlist:\n",
    "        counts[morpheme[0][2:]] = counts.get(morpheme[0][2:], 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def eval_labeled_positions(y_correct, y_pred):\n",
    "    # group the labels by morpheme and get list of morphemes\n",
    "    correctmorphs, _ = concatenateLabels(y_correct)\n",
    "    predmorphs, predLabels = concatenateLabels(y_pred)\n",
    "    # Count instances of each morpheme\n",
    "    test_morphcts = countMorphemes(correctmorphs)\n",
    "    pred_morphcts = countMorphemes(predmorphs)\n",
    "\n",
    "    correctMorphemects = {}\n",
    "    idx = 0\n",
    "    num_correct = 0\n",
    "    for morpheme in correctmorphs:\n",
    "        correct = True\n",
    "        for label in morpheme:\n",
    "            if label != predLabels[idx]:\n",
    "                correct = False\n",
    "            idx += 1\n",
    "        if correct == True:\n",
    "            num_correct += 1\n",
    "            correctMorphemects[morpheme[0][2:]] = correctMorphemects.get(morpheme[0][2:], 0) + 1\n",
    "    # calculate P, R F1 for each morpheme\n",
    "    results = ''\n",
    "    for firstlabel in correctMorphemects.keys():\n",
    "        lprec = correctMorphemects[firstlabel] / pred_morphcts[firstlabel]\n",
    "        lrecall = correctMorphemects[firstlabel] / test_morphcts[firstlabel]\n",
    "        results += firstlabel + '\\t\\t{0:.2f}'.format(lprec) + '\\t\\t' + '{0:.2f}'.format(\n",
    "            lrecall) + '\\t' + '{0:.2f}'.format((2 * lprec * lrecall) / (lprec + lrecall)) + '\\t\\t' + str(\n",
    "            test_morphcts[firstlabel]) + '\\n'\n",
    "    # overall results\n",
    "    precision = num_correct / len(predmorphs)\n",
    "    recall = num_correct / len(correctmorphs)\n",
    "\n",
    "    print('\\t\\tPrecision\\tRecall\\tf1-score\\tInstances\\n\\n' + results + '\\ntotal/avg\\t{0:.2f}'.format(\n",
    "        precision) + '\\t\\t' + '{0:.2f}'.format(recall) + '\\t' + '{0:.2f}'.format(\n",
    "        (2 * precision * recall) / (precision + recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen resultados del etiquetador por posición. Esto evalua que tan bien se desempeño el clasificador en cada morfema en su conjunto y sus etiquetas, en lugar de evaluar a nivel de caractéres. Luego, secompueban los resultados y se imprime un informe con los resultados. Estos resultados son a nivel de caracter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPrecision\tRecall\tf1-score\tInstances\n",
      "\n",
      "3.cpl\t\t0.97\t\t1.00\t0.98\t\t85\n",
      "stem\t\t0.96\t\t0.96\t0.96\t\t1484\n",
      "1.obj\t\t0.97\t\t0.97\t0.97\t\t33\n",
      "1.icp\t\t1.00\t\t1.00\t1.00\t\t58\n",
      "ctrf\t\t0.91\t\t0.98\t0.95\t\t63\n",
      "psd\t\t0.97\t\t0.99\t0.98\t\t73\n",
      "3.icp\t\t0.97\t\t0.98\t0.97\t\t58\n",
      "3.icp.irr\t\t1.00\t\t1.00\t1.00\t\t14\n",
      "lim\t\t1.00\t\t1.00\t1.00\t\t66\n",
      "prag\t\t1.00\t\t0.99\t0.99\t\t76\n",
      "1.pot\t\t0.98\t\t1.00\t0.99\t\t53\n",
      "1.pss\t\t1.00\t\t1.00\t1.00\t\t34\n",
      "dim\t\t0.87\t\t0.95\t0.91\t\t21\n",
      "3.pot\t\t1.00\t\t1.00\t1.00\t\t34\n",
      "3.prf\t\t0.92\t\t1.00\t0.96\t\t11\n",
      "det\t\t0.99\t\t0.99\t0.99\t\t158\n",
      "dem\t\t0.97\t\t0.97\t0.97\t\t36\n",
      "1.prf\t\t1.00\t\t1.00\t1.00\t\t20\n",
      "3.pls\t\t1.00\t\t1.00\t1.00\t\t11\n",
      "pl.exc\t\t0.90\t\t0.96\t0.93\t\t47\n",
      "loc\t\t1.00\t\t0.75\t0.86\t\t16\n",
      "mod\t\t0.86\t\t0.80\t0.83\t\t15\n",
      "lig\t\t0.88\t\t0.70\t0.78\t\t50\n",
      "1.cpl\t\t1.00\t\t1.00\t1.00\t\t36\n",
      "1.enf\t\t1.00\t\t1.00\t1.00\t\t7\n",
      "3.obj\t\t0.83\t\t0.59\t0.69\t\t17\n",
      "gen\t\t1.00\t\t0.33\t0.50\t\t3\n",
      "prt\t\t0.67\t\t0.14\t0.24\t\t14\n",
      "det.pl\t\t0.98\t\t1.00\t0.99\t\t55\n",
      "1.cnt\t\t1.00\t\t1.00\t1.00\t\t6\n",
      "dual.exc\t\t0.89\t\t1.00\t0.94\t\t8\n",
      "ila\t\t0.94\t\t1.00\t0.97\t\t33\n",
      "muy\t\t0.85\t\t0.85\t0.85\t\t13\n",
      "2.icp\t\t1.00\t\t1.00\t1.00\t\t14\n",
      "pl\t\t0.95\t\t0.71\t0.82\t\t28\n",
      "3.cnt\t\t0.90\t\t1.00\t0.95\t\t9\n",
      "it\t\t1.00\t\t0.89\t0.94\t\t9\n",
      "1.cpl.irr\t\t0.50\t\t1.00\t0.67\t\t1\n",
      "dual\t\t1.00\t\t1.00\t1.00\t\t4\n",
      "med\t\t0.83\t\t0.83\t0.83\t\t6\n",
      "3.imp\t\t1.00\t\t0.75\t0.86\t\t4\n",
      "pues\t\t1.00\t\t1.00\t1.00\t\t3\n",
      "int\t\t1.00\t\t0.80\t0.89\t\t5\n",
      "2.cnt\t\t1.00\t\t0.67\t0.80\t\t3\n",
      "2.pss\t\t1.00\t\t1.00\t1.00\t\t6\n",
      "3.pss\t\t0.67\t\t0.80\t0.73\t\t5\n",
      "toluca\t\t1.00\t\t1.00\t1.00\t\t2\n",
      "2.obj\t\t1.00\t\t0.60\t0.75\t\t5\n",
      "p.loc\t\t0.67\t\t0.50\t0.57\t\t4\n",
      "que\t\t1.00\t\t0.33\t0.50\t\t3\n",
      "2\t\t0.50\t\t1.00\t0.67\t\t1\n",
      "1.icp.irr\t\t1.00\t\t1.00\t1.00\t\t1\n",
      "1.pls\t\t1.00\t\t0.50\t0.67\t\t2\n",
      "\n",
      "total/avg\t0.96\t\t0.95\t0.95\n"
     ]
    }
   ],
   "source": [
    "eval_labeled_positions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_classification_report(y_correct, y_pred):\n",
    "    '''Takes list of correct and predicted labels from tagger.tag. \n",
    "    Prints a classification report for a list of BIO-encoded sequences.\n",
    "    It computes letter-level metrics.'''\n",
    "\n",
    "    labeler = LabelBinarizer()\n",
    "    y_correct_combined = labeler.fit_transform(list(chain.from_iterable(y_correct)))\n",
    "    y_pred_combined = labeler.transform(list(chain.from_iterable(y_pred)))\n",
    "    \n",
    "    tagset = set(labeler.classes_)\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(labeler.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_correct_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      B-1.cnt       1.00      1.00      1.00         6\n",
      "      I-1.cnt       1.00      1.00      1.00        12\n",
      "      B-1.cpl       1.00      1.00      1.00        36\n",
      "      I-1.cpl       1.00      1.00      1.00        36\n",
      "  B-1.cpl.irr       0.50      1.00      0.67         1\n",
      "  I-1.cpl.irr       0.50      1.00      0.67         1\n",
      "      B-1.enf       1.00      1.00      1.00         7\n",
      "      I-1.enf       1.00      1.00      1.00         7\n",
      "      B-1.icp       1.00      1.00      1.00        58\n",
      "      I-1.icp       1.00      1.00      1.00        58\n",
      "  B-1.icp.irr       1.00      1.00      1.00         1\n",
      "  I-1.icp.irr       1.00      1.00      1.00         2\n",
      "      B-1.irr       0.00      0.00      0.00         1\n",
      "      I-1.irr       0.00      0.00      0.00         2\n",
      "      B-1.obj       0.97      0.97      0.97        33\n",
      "      I-1.obj       0.97      0.97      0.97        33\n",
      "      B-1.pls       1.00      0.50      0.67         2\n",
      "      I-1.pls       1.00      0.50      0.67         2\n",
      "      B-1.pot       0.98      1.00      0.99        53\n",
      "      I-1.pot       0.98      1.00      0.99        53\n",
      "      B-1.prf       1.00      1.00      1.00        20\n",
      "      I-1.prf       1.00      1.00      1.00        20\n",
      "      B-1.pss       1.00      1.00      1.00        34\n",
      "      I-1.pss       1.00      1.00      1.00        34\n",
      "          B-2       0.50      1.00      0.67         1\n",
      "          I-2       0.50      1.00      0.67         1\n",
      "      B-2.cnt       1.00      0.67      0.80         3\n",
      "      I-2.cnt       1.00      0.67      0.80         6\n",
      "      B-2.cpl       0.00      0.00      0.00         2\n",
      "      I-2.cpl       0.00      0.00      0.00         2\n",
      "      B-2.icp       1.00      1.00      1.00        14\n",
      "      I-2.icp       1.00      1.00      1.00        14\n",
      "      B-2.obj       1.00      0.60      0.75         5\n",
      "      I-2.obj       1.00      0.75      0.86         8\n",
      "      B-2.pss       1.00      1.00      1.00         6\n",
      "      I-2.pss       1.00      1.00      1.00         6\n",
      "      B-3.cnt       0.90      1.00      0.95         9\n",
      "      I-3.cnt       0.90      1.00      0.95         9\n",
      "      B-3.cpl       0.97      1.00      0.98        85\n",
      "      I-3.cpl       0.97      1.00      0.98        85\n",
      "  B-3.cpl.irr       0.00      0.00      0.00         1\n",
      "  I-3.cpl.irr       0.00      0.00      0.00         2\n",
      "      B-3.icp       0.97      0.98      0.97        58\n",
      "      I-3.icp       0.00      0.00      0.00         1\n",
      "  B-3.icp.irr       1.00      1.00      1.00        14\n",
      "  I-3.icp.irr       1.00      1.00      1.00        14\n",
      "      B-3.imp       1.00      0.75      0.86         4\n",
      "      I-3.imp       1.00      0.75      0.86         8\n",
      "      B-3.irr       0.00      0.00      0.00         1\n",
      "      I-3.irr       0.00      0.00      0.00         1\n",
      "      B-3.obj       0.83      0.59      0.69        17\n",
      "      I-3.obj       0.83      0.56      0.67        18\n",
      "      B-3.pls       1.00      1.00      1.00        11\n",
      "      I-3.pls       1.00      1.00      1.00        11\n",
      "      B-3.pot       1.00      1.00      1.00        34\n",
      "      I-3.pot       1.00      1.00      1.00        34\n",
      "      B-3.prf       0.92      1.00      0.96        11\n",
      "      I-3.prf       0.92      1.00      0.96        11\n",
      "      B-3.pss       0.67      0.80      0.73         5\n",
      "      I-3.pss       0.67      0.80      0.73         5\n",
      "       B-3.sg       0.00      0.00      0.00         2\n",
      "       I-3.sg       0.00      0.00      0.00         6\n",
      "        B-adj       0.00      0.00      0.00         1\n",
      "        I-adj       0.00      0.00      0.00         1\n",
      "B-agujerear/v       0.00      0.00      0.00         1\n",
      "I-agujerear/v       0.00      0.00      0.00         3\n",
      "        B-aum       0.00      0.00      0.00         2\n",
      "        I-aum       0.00      0.00      0.00         4\n",
      "       B-como       0.00      0.00      0.00         2\n",
      "       I-como       0.00      0.00      0.00         2\n",
      "        B-con       0.00      0.00      0.00         1\n",
      "        I-con       0.00      0.00      0.00         2\n",
      "       B-cond       0.00      0.00      0.00         1\n",
      "       I-cond       0.00      0.00      0.00         1\n",
      "   B-conj.adv       0.00      0.00      0.00         1\n",
      "       B-ctrf       0.91      0.98      0.95        63\n",
      "       I-ctrf       0.91      0.98      0.95        63\n",
      "     B-cuando       0.00      0.00      0.00         1\n",
      "     I-cuando       0.00      0.00      0.00         1\n",
      "        B-dem       0.97      0.97      0.97        36\n",
      "        I-dem       0.97      0.97      0.97        58\n",
      "        B-det       0.99      0.99      0.99       158\n",
      "        I-det       0.99      0.99      0.99       159\n",
      "     B-det.pl       0.98      1.00      0.99        55\n",
      "     I-det.pl       0.98      1.00      0.99        56\n",
      "        B-dim       0.87      0.95      0.91        21\n",
      "        I-dim       0.87      0.95      0.91        42\n",
      "       B-dual       1.00      1.00      1.00         4\n",
      "       I-dual       1.00      1.00      1.00         4\n",
      "   B-dual.exc       0.89      1.00      0.94         8\n",
      "   I-dual.exc       0.89      1.00      0.94         8\n",
      "        B-gen       1.00      0.33      0.50         3\n",
      "        I-gen       1.00      0.33      0.50         6\n",
      "        B-ila       0.94      1.00      0.97        33\n",
      "        I-ila       0.94      1.00      0.97        66\n",
      "        B-int       1.00      0.80      0.89         5\n",
      "        I-int       1.00      0.67      0.80         6\n",
      "         B-it       1.00      0.89      0.94         9\n",
      "         I-it       1.00      0.89      0.94         9\n",
      "        B-lig       0.88      0.70      0.78        50\n",
      "        B-lim       1.00      1.00      1.00        66\n",
      "        I-lim       1.00      1.00      1.00       129\n",
      "        B-loc       1.00      0.75      0.86        16\n",
      "        I-loc       1.00      0.83      0.91        29\n",
      "        B-med       0.83      0.83      0.83         6\n",
      "   B-mientras       0.00      0.00      0.00         1\n",
      "   I-mientras       0.00      0.00      0.00         3\n",
      "        B-mod       0.86      0.80      0.83        15\n",
      "        I-mod       0.88      0.81      0.85        27\n",
      "        B-muy       0.85      0.85      0.85        13\n",
      "        I-muy       0.85      0.85      0.85        26\n",
      "      B-p.loc       0.67      0.50      0.57         4\n",
      "      I-p.loc       0.67      0.50      0.57         4\n",
      "         B-pl       0.95      0.71      0.82        28\n",
      "         I-pl       0.95      0.71      0.82        28\n",
      "     B-pl.exc       0.90      0.96      0.93        47\n",
      "     I-pl.exc       0.90      0.96      0.93        47\n",
      "       B-prag       1.00      0.99      0.99        76\n",
      "       I-prag       1.00      0.99      0.99        76\n",
      "        B-prt       0.67      0.14      0.24        14\n",
      "        I-prt       0.29      0.11      0.16        18\n",
      "        B-psd       0.97      0.99      0.98        73\n",
      "     B-pueblo       0.00      0.00      0.00         1\n",
      "     I-pueblo       0.00      0.00      0.00         4\n",
      "       B-pues       1.00      1.00      1.00         3\n",
      "       I-pues       1.00      1.00      1.00         3\n",
      "        B-que       1.00      0.33      0.50         3\n",
      "        I-que       1.00      0.33      0.50         3\n",
      "         B-si       0.00      0.00      0.00         1\n",
      "         I-si       0.00      0.00      0.00         1\n",
      "       B-solo       0.00      0.00      0.00         1\n",
      "       I-solo       0.00      0.00      0.00         2\n",
      "        B-spt       0.00      0.00      0.00         1\n",
      "        I-spt       0.00      0.00      0.00         1\n",
      "       B-stem       0.97      0.97      0.97      1485\n",
      "       I-stem       0.96      0.99      0.97      4076\n",
      "     B-toluca       1.00      1.00      1.00         2\n",
      "     I-toluca       1.00      1.00      1.00        12\n",
      "          B-y       0.00      0.00      0.00         3\n",
      "          I-y       0.00      0.00      0.00         1\n",
      "\n",
      "    micro avg       0.96      0.96      0.96      8332\n",
      "    macro avg       0.68      0.64      0.64      8332\n",
      " weighted avg       0.95      0.96      0.96      8332\n",
      "  samples avg       0.96      0.96      0.96      8332\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umoqnier/develop/tesis/workouts/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/umoqnier/develop/tesis/workouts/env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_transitions(trans_features):\n",
    "    '''Print info from the crfsuite.'''\n",
    "    \n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-6s %s\" % (weight, label, attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-stem -> I-stem  10.934023\n",
      "I-stem -> I-stem  8.395278\n",
      "B-com  -> I-com   6.823475\n",
      "B-neg  -> I-neg   6.721609\n",
      "B-1.cnt -> I-1.cnt 6.630173\n",
      "B-det  -> I-det   6.510363\n",
      "B-3.pot -> I-3.pot 6.368820\n",
      "B-lim  -> I-lim   6.278319\n",
      "B-prt  -> I-prt   6.276504\n",
      "B-dem  -> I-dem   5.959775\n",
      "I-neg  -> I-neg   5.840462\n",
      "B-mod  -> I-mod   5.839273\n",
      "B-3.imp -> I-3.imp 5.748112\n",
      "B-loc  -> I-loc   5.740772\n",
      "B-2.icp -> I-2.icp 5.711878\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-stem -> B-3.icp -0.006762\n",
      "I-stem -> B-muy   -0.006980\n",
      "I-dem  -> B-psd   -0.008274\n",
      "I-aum  -> B-stem  -0.009441\n",
      "I-dem  -> B-stem  -0.030308\n",
      "I-pascuala -> B-stem  -0.030714\n",
      "I-stem -> B-3.cpl -0.037465\n",
      "I-stem -> B-3.prf -0.054174\n",
      "I-loc  -> B-stem  -0.093922\n",
      "I-stem -> B-ctrf  -0.151861\n",
      "I-ila  -> B-stem  -0.169774\n",
      "I-stem -> B-stem  -0.393821\n",
      "I-1.obj -> B-stem  -0.402426\n",
      "I-3.obj -> B-stem  -0.623276\n",
      "I-prag -> B-stem  -0.972304\n",
      "Top positive:\n",
      "5.918738 I-1.cnt prev2letters=dr>\n",
      "5.606847 I-stem EOW\n",
      "5.132919 B-stem BOW\n",
      "4.933950 B-1.pss nxtletter=<ä\n",
      "4.855952 B-3.icp BOW\n",
      "4.645045 B-det.pl postag=det\n",
      "4.600537 B-det.pl letterLowercase=y\n",
      "4.598223 B-lig  letterLowercase=h\n",
      "4.549079 I-det.pl postag=det\n",
      "4.413653 I-det  postag=det\n",
      "4.188902 I-det.dem postag=det\n",
      "4.065331 B-psd  BOW\n",
      "4.050548 I-3.icp prevletter=b>\n",
      "3.823828 I-3.cpl prevletter=b>\n",
      "3.821892 I-lim  prevletter=ι>\n",
      "\n",
      "Top negative:\n",
      "-1.338388 I-stem prev2letters=na>\n",
      "-1.392051 B-det  postag=v\n",
      "-1.397450 B-stem nxtletter=<ι\n",
      "-1.401359 B-stem postag=n\n",
      "-1.465503 I-stem letterLowercase=p\n",
      "-1.523044 I-stem prev2letters=pe>\n",
      "-1.549475 B-3.icp bias\n",
      "-1.590518 I-det  postag=v\n",
      "-1.605653 B-stem letterposition=-1\n",
      "-1.724536 I-stem prev3letters=khá>\n",
      "-2.277437 B-prag postag=n\n",
      "-2.345684 I-prag postag=n\n",
      "-2.420029 I-ctrf EOW\n",
      "-2.533985 B-stem postag=v\n",
      "-2.930720 I-stem bias\n"
     ]
    }
   ],
   "source": [
    "info = tagger.info()\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])\n",
    "\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(info.state_features).most_common(15))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(info.state_features).most_common()[-15:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesis Kernel",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
