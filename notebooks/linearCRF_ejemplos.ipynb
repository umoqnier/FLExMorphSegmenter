{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos del Linear Chain CRF\n",
    "\n",
    "### Nombre\n",
    "\n",
    "* linearCRF_l2_zero_50_0.1_0_k_10.crfsuite\n",
    "\n",
    "### Parametros\n",
    "\n",
    "* l1 = 0.1\n",
    "* l2 = 0\n",
    "* Precisión general = 0.9516\n",
    "* Max_Iter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycrfsuite\n",
    "import sys  \n",
    "import random\n",
    "sys.path.insert(0, '../')\n",
    "from utils import get_corpus, WordsToLetter, extractLabels, extractTokens\n",
    "from corpus_utils import oto_glosser\n",
    "model = \"linearCRF_l2_zero_50_0.1_0_k_10.crfsuite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"../models/linearChainCRFs\",\n",
    "                          \"tsu_\" + model)\n",
    "print(model_path)\n",
    "tagger = pycrfsuite.Tagger()\n",
    "# Cargando modelos preentrenados\n",
    "tagger.open(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obteniendo corpus para pruebas\n",
    "corpus = get_corpus('corpus_otomi_mod', '../corpora/') + \\\n",
    "         get_corpus('corpus_hard', '../corpora/')\n",
    "letter_corpus = WordsToLetter(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones auxiliares\n",
    "def obtener_palabras(frases):\n",
    "    palabras = []\n",
    "    for frase in frases:\n",
    "        chunks = [palabra[0] for palabra in frase[:-1]]\n",
    "        palabras.append(\"\".join(chunks))\n",
    "    return palabras\n",
    "\n",
    "def reporte(prediction_tags, real_tags, example):\n",
    "    print(\"Letra | Predicción | Real | Es correcto?\")\n",
    "    for prediction, real, letter in zip(prediction_tags, real_tags, extractTokens(example)):\n",
    "        print(f\"{letter} | {prediction} | {real} | {True if prediction == real else False}\")\n",
    "        \n",
    "def accuracy_score(y_test, y_pred):\n",
    "    right, total = 0, 0\n",
    "    for real, prediction in zip(y_test, y_pred):\n",
    "        if real == prediction:\n",
    "            right += 1\n",
    "    return right / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_functions_maker(sent):\n",
    "    ''' Reglas que configuran las feature functions para entrenamiento\n",
    "\n",
    "    :param sent: Data as `[[[[[letter, POS, BIO-label],...],words],sents]]`\n",
    "    :type: list\n",
    "    :return: list of words with characters as features list:\n",
    "        [[[[[letterfeatures],POS,BIO-label],letters],words]]\n",
    "    :rtype: list\n",
    "    '''\n",
    "\n",
    "    featurelist = []\n",
    "    senlen = len(sent)\n",
    "    # each word in a sentence\n",
    "    for i in range(senlen):\n",
    "        word = sent[i]\n",
    "        wordlen = len(word)\n",
    "        lettersequence = ''\n",
    "        # each letter in a word\n",
    "        for j in range(wordlen):\n",
    "            letter = word[j][0]\n",
    "            # gathering previous letters\n",
    "            lettersequence += letter\n",
    "            # ignore digits\n",
    "            if not letter.isdigit():\n",
    "                features = [\n",
    "                    'bias',\n",
    "                    'letterLowercase=' + letter.lower(),\n",
    "                ]\n",
    "                # Position of word in sentence\n",
    "                if i == senlen -1:\n",
    "                    features.append(\"EOS\")\n",
    "                else:\n",
    "                    features.append(\"BOS\")\n",
    "\n",
    "                # Pos tag sequence (Don't get pos tag if sentence is 1 word long)\n",
    "                if i > 0 and senlen > 1:\n",
    "                    features.append('prevpostag=' + sent[i-1][0][1])\n",
    "                    if i != senlen-1:\n",
    "                        features.append('nxtpostag=' + sent[i+1][0][1])\n",
    "\n",
    "                # Position of letter in word\n",
    "                if j == 0:\n",
    "                    features.append('BOW')\n",
    "                elif j == wordlen-1:\n",
    "                    features.append('EOW')\n",
    "                else:\n",
    "                    features.append('letterposition=-%s' % str(wordlen-1-j))\n",
    "\n",
    "                # Letter sequences before letter\n",
    "                if j >= 4:\n",
    "                    features.append('prev4letters=' + lettersequence[j-4:j].lower() + '>')\n",
    "                if j >= 3:\n",
    "                    features.append('prev3letters=' + lettersequence[j-3:j].lower() + '>')\n",
    "                if j >= 2:\n",
    "                    features.append('prev2letters=' + lettersequence[j-2:j].lower() + '>')\n",
    "                if j >= 1:\n",
    "                    features.append('prevletter=' + lettersequence[j-1:j].lower() + '>')\n",
    "\n",
    "                # letter sequences after letter\n",
    "                if j <= wordlen-2:\n",
    "                    nxtlets = word[j+1][0]\n",
    "                    features.append('nxtletter=<' + nxtlets.lower())\n",
    "                if j <= wordlen-3:\n",
    "                    nxtlets += word[j+2][0]\n",
    "                    features.append('nxt2letters=<' + nxtlets.lower())\n",
    "                if j <= wordlen-4:\n",
    "                    nxtlets += word[j+3][0]\n",
    "                    features.append('nxt3letters=<' + nxtlets.lower())\n",
    "                if j <= wordlen-5:\n",
    "                    nxtlets += word[j+4][0]\n",
    "                    features.append('nxt4letters=<' + nxtlets.lower())\n",
    "\n",
    "            # Add encoding for pysrfsuite\n",
    "            featurelist.append([f.encode('utf-8') for f in features])\n",
    "    return featurelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los peores ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peores = []\n",
    "for i, example in enumerate(letter_corpus):\n",
    "    feature_functions = feature_functions_maker(example)    \n",
    "    prediction_tags = tagger.tag(feature_functions)      \n",
    "    real_tags = extractLabels(example, 1)\n",
    "    accuracy = accuracy_score(real_tags, prediction_tags)\n",
    "    if accuracy <= 0.8:\n",
    "        peores.append((i, accuracy))\n",
    "peores = sorted(peores, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos los 5 peores\n",
    "top = peores[5:10]\n",
    "for i, data in enumerate(top):\n",
    "    print(\"-\"*50)\n",
    "    index = data[0]\n",
    "    palabras = obtener_palabras(corpus[index])\n",
    "    example = letter_corpus[index]\n",
    "    features = feature_functions_maker(example)\n",
    "    prediction_tags = tagger.tag(features)\n",
    "    real_tags = extractLabels(example, 1)\n",
    "    print(f\"Ejemplo {i+1} de 5 | Frase: \\\"{' '.join(palabras)}\\\" | Accuracy: {data[1]}\")\n",
    "    reporte(prediction_tags, real_tags, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los mejores\n",
    "\n",
    "Como de estos hay muchos vamos a tomar 3 al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 0\n",
    "while flag != 3:\n",
    "    print(\"-\"*50)\n",
    "    index = random.randint(0, len(letter_corpus))\n",
    "    palabras = obtener_palabras(corpus[index])\n",
    "    example = letter_corpus[index]\n",
    "    features = feature_functions_maker(example)\n",
    "    prediction_tags = tagger.tag(features)\n",
    "    real_tags = extractLabels(example, 1)\n",
    "    accuracy = accuracy_score(real_tags, prediction_tags)\n",
    "    if accuracy >= 0.99:\n",
    "        print(f\"Ejemplo {flag + 1} de 3 | Frase: \\\"{' '.join(palabras)}\\\" | Precisión: {accuracy}\")\n",
    "        reporte(prediction_tags, real_tags, example)\n",
    "        flag += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obteniendo las frases mas largas y mejor etiquetadas\n",
    "min_len = 30\n",
    "phrases = []\n",
    "for i, example in enumerate(letter_corpus):\n",
    "    features = feature_functions_maker(example)\n",
    "    palabras = obtener_palabras(corpus[i])\n",
    "    prediction_tags = tagger.tag(features)\n",
    "    real_tags = extractLabels(example, 1)\n",
    "    accuracy = accuracy_score(real_tags, prediction_tags)\n",
    "    if accuracy >= 0.99:\n",
    "        if len(\"\".join(palabras)) >= min_len:\n",
    "            predicted_gloss = oto_glosser(palabras, prediction_tags, corpus[i])\n",
    "            phrases.append((palabras, predicted_gloss, i, accuracy))\n",
    "print(phrases[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"mejores-frases-linearCRF.csv\", \"w\") as csvfile:\n",
    "    header = [\"frase\", \"glosa_predicha\", \"glosa_real\", \"eq?\",'accuracy-score']\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for phrase in phrases:\n",
    "        writer.writerow([\" \".join(phrase[0]), str(phrase[1]),\n",
    "                         corpus[phrase[2]], phrase[1] == corpus[phrase[2]],\n",
    "                         phrase[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obteniendo las frases mas largas y mejor etiquetadas\n",
    "min_len = 0\n",
    "phrases = []\n",
    "for i, example in enumerate(letter_corpus):\n",
    "    features = feature_functions_maker(example)\n",
    "    palabras = obtener_palabras(corpus[i])\n",
    "    prediction_tags = tagger.tag(features)\n",
    "    real_tags = extractLabels(example, 1)\n",
    "    accuracy = accuracy_score(real_tags, prediction_tags)\n",
    "    if accuracy <= 0.80:\n",
    "        if len(\" \".join(palabras)) >= min_len:\n",
    "            predicted_gloss = oto_glosser(palabras, prediction_tags, corpus[i])\n",
    "            phrases.append((palabras, predicted_gloss, i, accuracy))\n",
    "print(phrases[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"peores-frases-linearCRF.csv\", \"w\") as csvfile:\n",
    "    header = [\"frase\", \"glosa predicha\", \"glosa real\", 'accuracy-score']\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    for phrase in phrases:\n",
    "        writer.writerow([\" \".join(phrase[0]), str(phrase[1]),\n",
    "                         corpus[phrase[2]], phrase[1] == corpus[phrase[2]],\n",
    "                         phrase[3]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesis Kernel",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
